{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75bc5a52",
   "metadata": {},
   "source": [
    "## Exploring the speed-up in Scikit-Learn ML algorithms from Intel® Extension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b712820b",
   "metadata": {},
   "source": [
    "Begin in the usual way by importing a load of packages and methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88aa821a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.0.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, time, warnings\n",
    "\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "\n",
    "import sklearn\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c748806f",
   "metadata": {},
   "source": [
    "Create a synthetic dataset (100k rows x 50 columns) with binary class labels to use for these tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "303502c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature0</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature41</th>\n",
       "      <th>feature42</th>\n",
       "      <th>feature43</th>\n",
       "      <th>feature44</th>\n",
       "      <th>feature45</th>\n",
       "      <th>feature46</th>\n",
       "      <th>feature47</th>\n",
       "      <th>feature48</th>\n",
       "      <th>feature49</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.669705</td>\n",
       "      <td>0.086077</td>\n",
       "      <td>-0.018661</td>\n",
       "      <td>-1.775734</td>\n",
       "      <td>0.306349</td>\n",
       "      <td>-0.016481</td>\n",
       "      <td>1.547228</td>\n",
       "      <td>-1.033515</td>\n",
       "      <td>-0.826289</td>\n",
       "      <td>-0.608985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.682215</td>\n",
       "      <td>-0.084760</td>\n",
       "      <td>0.462544</td>\n",
       "      <td>0.505429</td>\n",
       "      <td>-1.819447</td>\n",
       "      <td>0.423849</td>\n",
       "      <td>-0.577485</td>\n",
       "      <td>0.048307</td>\n",
       "      <td>2.512233</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.883471</td>\n",
       "      <td>-0.349887</td>\n",
       "      <td>-1.043696</td>\n",
       "      <td>-1.065610</td>\n",
       "      <td>1.788755</td>\n",
       "      <td>-0.327026</td>\n",
       "      <td>-0.578242</td>\n",
       "      <td>-0.458330</td>\n",
       "      <td>-0.959961</td>\n",
       "      <td>-0.474877</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.952969</td>\n",
       "      <td>1.094819</td>\n",
       "      <td>-0.840477</td>\n",
       "      <td>-1.468307</td>\n",
       "      <td>-0.522779</td>\n",
       "      <td>0.849929</td>\n",
       "      <td>1.026037</td>\n",
       "      <td>0.422189</td>\n",
       "      <td>0.174214</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.794821</td>\n",
       "      <td>-0.575405</td>\n",
       "      <td>-1.048310</td>\n",
       "      <td>0.626764</td>\n",
       "      <td>-1.252084</td>\n",
       "      <td>-2.068356</td>\n",
       "      <td>-1.049785</td>\n",
       "      <td>0.198632</td>\n",
       "      <td>-0.037818</td>\n",
       "      <td>2.492830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.680952</td>\n",
       "      <td>2.944942</td>\n",
       "      <td>0.018258</td>\n",
       "      <td>1.618344</td>\n",
       "      <td>2.226057</td>\n",
       "      <td>-1.113022</td>\n",
       "      <td>0.812983</td>\n",
       "      <td>-0.958635</td>\n",
       "      <td>0.310898</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.645206</td>\n",
       "      <td>-0.636342</td>\n",
       "      <td>-1.045645</td>\n",
       "      <td>0.388528</td>\n",
       "      <td>-1.429646</td>\n",
       "      <td>0.095641</td>\n",
       "      <td>0.558399</td>\n",
       "      <td>-1.521681</td>\n",
       "      <td>-0.754305</td>\n",
       "      <td>1.011399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.473084</td>\n",
       "      <td>0.802118</td>\n",
       "      <td>-0.622393</td>\n",
       "      <td>0.959843</td>\n",
       "      <td>-1.350125</td>\n",
       "      <td>0.559151</td>\n",
       "      <td>1.913058</td>\n",
       "      <td>1.457666</td>\n",
       "      <td>-0.246192</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.773496</td>\n",
       "      <td>0.154083</td>\n",
       "      <td>0.290622</td>\n",
       "      <td>-0.388261</td>\n",
       "      <td>1.850270</td>\n",
       "      <td>1.719226</td>\n",
       "      <td>0.589777</td>\n",
       "      <td>-0.583710</td>\n",
       "      <td>1.752810</td>\n",
       "      <td>-0.563795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.819008</td>\n",
       "      <td>0.102735</td>\n",
       "      <td>0.086873</td>\n",
       "      <td>1.765650</td>\n",
       "      <td>2.187963</td>\n",
       "      <td>-0.607109</td>\n",
       "      <td>0.989692</td>\n",
       "      <td>-0.292819</td>\n",
       "      <td>0.692844</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>0.626010</td>\n",
       "      <td>0.442061</td>\n",
       "      <td>0.288279</td>\n",
       "      <td>0.042049</td>\n",
       "      <td>0.116108</td>\n",
       "      <td>0.800749</td>\n",
       "      <td>0.061629</td>\n",
       "      <td>0.264332</td>\n",
       "      <td>0.665570</td>\n",
       "      <td>-0.132450</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.109036</td>\n",
       "      <td>-0.816004</td>\n",
       "      <td>2.538606</td>\n",
       "      <td>0.063116</td>\n",
       "      <td>2.606622</td>\n",
       "      <td>-0.135536</td>\n",
       "      <td>-0.724261</td>\n",
       "      <td>0.572397</td>\n",
       "      <td>0.534640</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>2.052267</td>\n",
       "      <td>-0.530247</td>\n",
       "      <td>0.293953</td>\n",
       "      <td>1.465093</td>\n",
       "      <td>-0.916418</td>\n",
       "      <td>0.653121</td>\n",
       "      <td>-0.025018</td>\n",
       "      <td>1.289437</td>\n",
       "      <td>-0.248062</td>\n",
       "      <td>0.750218</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.648375</td>\n",
       "      <td>-0.942992</td>\n",
       "      <td>0.207127</td>\n",
       "      <td>-0.316615</td>\n",
       "      <td>-0.712754</td>\n",
       "      <td>0.794594</td>\n",
       "      <td>0.929845</td>\n",
       "      <td>-2.160133</td>\n",
       "      <td>0.568293</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>0.891679</td>\n",
       "      <td>-0.672638</td>\n",
       "      <td>-0.047065</td>\n",
       "      <td>-0.793157</td>\n",
       "      <td>0.142738</td>\n",
       "      <td>-0.331786</td>\n",
       "      <td>-1.577147</td>\n",
       "      <td>0.443885</td>\n",
       "      <td>-1.876038</td>\n",
       "      <td>1.174218</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.788905</td>\n",
       "      <td>-0.788862</td>\n",
       "      <td>0.419097</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>1.011735</td>\n",
       "      <td>0.903432</td>\n",
       "      <td>-0.146275</td>\n",
       "      <td>-1.614053</td>\n",
       "      <td>-0.868440</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>-0.436063</td>\n",
       "      <td>-2.313270</td>\n",
       "      <td>-1.291914</td>\n",
       "      <td>-1.425559</td>\n",
       "      <td>0.644533</td>\n",
       "      <td>0.749082</td>\n",
       "      <td>-0.823566</td>\n",
       "      <td>-0.194106</td>\n",
       "      <td>0.846408</td>\n",
       "      <td>-0.369556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795921</td>\n",
       "      <td>-1.053190</td>\n",
       "      <td>-0.035781</td>\n",
       "      <td>0.283431</td>\n",
       "      <td>-3.329111</td>\n",
       "      <td>0.053290</td>\n",
       "      <td>-2.060886</td>\n",
       "      <td>-0.964378</td>\n",
       "      <td>-0.077709</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>2.741748</td>\n",
       "      <td>-0.911624</td>\n",
       "      <td>0.247177</td>\n",
       "      <td>-0.555973</td>\n",
       "      <td>-1.018039</td>\n",
       "      <td>1.201913</td>\n",
       "      <td>-0.765548</td>\n",
       "      <td>1.862372</td>\n",
       "      <td>0.746808</td>\n",
       "      <td>-1.008706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>-1.375389</td>\n",
       "      <td>0.369157</td>\n",
       "      <td>-0.407704</td>\n",
       "      <td>0.649478</td>\n",
       "      <td>0.018835</td>\n",
       "      <td>-1.147871</td>\n",
       "      <td>2.248993</td>\n",
       "      <td>0.073812</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature0  feature1  feature2  feature3  feature4  feature5  feature6  \\\n",
       "0      -1.669705  0.086077 -0.018661 -1.775734  0.306349 -0.016481  1.547228   \n",
       "1      -0.883471 -0.349887 -1.043696 -1.065610  1.788755 -0.327026 -0.578242   \n",
       "2       0.794821 -0.575405 -1.048310  0.626764 -1.252084 -2.068356 -1.049785   \n",
       "3      -2.645206 -0.636342 -1.045645  0.388528 -1.429646  0.095641  0.558399   \n",
       "4      -0.773496  0.154083  0.290622 -0.388261  1.850270  1.719226  0.589777   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "999995  0.626010  0.442061  0.288279  0.042049  0.116108  0.800749  0.061629   \n",
       "999996  2.052267 -0.530247  0.293953  1.465093 -0.916418  0.653121 -0.025018   \n",
       "999997  0.891679 -0.672638 -0.047065 -0.793157  0.142738 -0.331786 -1.577147   \n",
       "999998 -0.436063 -2.313270 -1.291914 -1.425559  0.644533  0.749082 -0.823566   \n",
       "999999  2.741748 -0.911624  0.247177 -0.555973 -1.018039  1.201913 -0.765548   \n",
       "\n",
       "        feature7  feature8  feature9  ...  feature41  feature42  feature43  \\\n",
       "0      -1.033515 -0.826289 -0.608985  ...   0.682215  -0.084760   0.462544   \n",
       "1      -0.458330 -0.959961 -0.474877  ...  -0.952969   1.094819  -0.840477   \n",
       "2       0.198632 -0.037818  2.492830  ...   0.680952   2.944942   0.018258   \n",
       "3      -1.521681 -0.754305  1.011399  ...  -0.473084   0.802118  -0.622393   \n",
       "4      -0.583710  1.752810 -0.563795  ...   0.819008   0.102735   0.086873   \n",
       "...          ...       ...       ...  ...        ...        ...        ...   \n",
       "999995  0.264332  0.665570 -0.132450  ...  -1.109036  -0.816004   2.538606   \n",
       "999996  1.289437 -0.248062  0.750218  ...  -0.648375  -0.942992   0.207127   \n",
       "999997  0.443885 -1.876038  1.174218  ...  -0.788905  -0.788862   0.419097   \n",
       "999998 -0.194106  0.846408 -0.369556  ...   0.795921  -1.053190  -0.035781   \n",
       "999999  1.862372  0.746808 -1.008706  ...   0.005051  -1.375389   0.369157   \n",
       "\n",
       "        feature44  feature45  feature46  feature47  feature48  feature49  \\\n",
       "0        0.505429  -1.819447   0.423849  -0.577485   0.048307   2.512233   \n",
       "1       -1.468307  -0.522779   0.849929   1.026037   0.422189   0.174214   \n",
       "2        1.618344   2.226057  -1.113022   0.812983  -0.958635   0.310898   \n",
       "3        0.959843  -1.350125   0.559151   1.913058   1.457666  -0.246192   \n",
       "4        1.765650   2.187963  -0.607109   0.989692  -0.292819   0.692844   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "999995   0.063116   2.606622  -0.135536  -0.724261   0.572397   0.534640   \n",
       "999996  -0.316615  -0.712754   0.794594   0.929845  -2.160133   0.568293   \n",
       "999997   0.254265   1.011735   0.903432  -0.146275  -1.614053  -0.868440   \n",
       "999998   0.283431  -3.329111   0.053290  -2.060886  -0.964378  -0.077709   \n",
       "999999  -0.407704   0.649478   0.018835  -1.147871   2.248993   0.073812   \n",
       "\n",
       "        Target  \n",
       "0            1  \n",
       "1            1  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "...        ...  \n",
       "999995       1  \n",
       "999996       1  \n",
       "999997       1  \n",
       "999998       0  \n",
       "999999       1  \n",
       "\n",
       "[1000000 rows x 51 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features,labels = sklearn.datasets.make_classification(n_samples=1000_000, n_features=50)\n",
    "\n",
    "cols_ml = ['feature'+str(x) for x in range(50)]\n",
    "\n",
    "# for convenience let's put it all together in a pandas dataframe:\n",
    "dataset = pd.DataFrame(data=features, columns=cols_ml)\n",
    "dataset['Target'] = labels\n",
    "\n",
    "# inspect the resulting dataframe\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a9e4e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97ce24dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8 s ± 76.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "dataset[cols_ml] = scaler.fit_transform(dataset[cols_ml])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a130aa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when using timeit I do each operation a second time to get the output\n",
    "dataset[cols_ml] = scaler.fit_transform(dataset[cols_ml])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf5be60",
   "metadata": {},
   "source": [
    "Calculate and apply a PCA transform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a87e3eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221 ms ± 17.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "dimReducer = PCA(n_components=10)\n",
    "result = dimReducer.fit_transform(dataset[cols_ml].to_numpy())\n",
    "# the result isn't used for anything in this notebook, but the test ins included for interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44afeba6",
   "metadata": {},
   "source": [
    "**This task is more than 1000x times faster with the Intel extension!**\n",
    "\n",
    "Do a train / test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a581219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283 ms ± 6.49 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset[cols_ml].to_numpy(),dataset['Target'].to_numpy(),test_size=0.3,random_state=1984)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db4ace4",
   "metadata": {},
   "source": [
    "Here there's no significant improvement from using the Intel extension, but this could be due to the properties of the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a67c9971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to avoid waiting too long for the classifiers to train, let's downsample the data from 1m to 20k rows\n",
    "dataset = dataset.sample(n=20_000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset[cols_ml],dataset['Target'],test_size=0.3,random_state=1984)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bb1404",
   "metadata": {},
   "source": [
    "Fit a random forest classifier and predict classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1912af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=1000,n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c5658a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.58 s ± 198 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c7c993",
   "metadata": {},
   "source": [
    "**Wow, about 10x faster!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83d020ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=1000, n_jobs=4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef91074b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296 ms ± 10.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "preds = clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc94ba4",
   "metadata": {},
   "source": [
    "No real improvement in the prediction of classes (basically all the hard CPU / GPU work was done already by the .fit method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10199512",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b206d5aa",
   "metadata": {},
   "source": [
    "Now let's try the `KNeighborsClassifier`. Note that KNN is a 'lazy' method, so most of the work is done predicting rather than training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea8748d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f13b0978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.16 ms ± 137 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a1703c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_jobs=4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac4389b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 ms ± 2.02 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "preds = clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e192f95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7554b36",
   "metadata": {},
   "source": [
    "**In this case, the speed-up is an enormous x1000, from ~5 seconds to ~5 millseconds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06485e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py39] *",
   "language": "python",
   "name": "conda-env-py39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
